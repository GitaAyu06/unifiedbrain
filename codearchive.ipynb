{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activation=F.relu):\n",
    "        super(GAT, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "        self.phi = nn.Parameter(torch.FloatTensor(2 * out_features, 1))\n",
    "        self.activation = activation\n",
    "        self.reset_parameters()\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    " \n",
    "    def reset_parameters(self):\n",
    "        uniform(weight)\n",
    "        uniform(phi)\n",
    " \n",
    "    def forward(self, input, adj):\n",
    "        input = self.drop(input)\n",
    "        h = torch.mm(input, self.weight) + self.bias \n",
    " \n",
    "        N = input.size(0) \n",
    "        h_expand = h.unsqueeze(1).expand(N, N, -1)\n",
    "        h_t_expand = h.unsqueeze(0).expand(N, N, -1)\n",
    "        \n",
    "        concat_features = torch.cat([h_expand, h_t_expand], dim=-1)\n",
    "        \n",
    "        S = torch.matmul(concat_features, self.phi).squeeze(-1)\n",
    " \n",
    "        mask = (adj.to(device) + torch.eye(adj.size(0),device=device)).bool()\n",
    "        S_masked = torch.where(mask, S, torch.tensor(-9e15, dtype=S.dtype).to(device))\n",
    "        attention_weights = F.softmax(S_masked, dim=1)\n",
    "        h = torch.matmul(attention_weights, h)\n",
    "        return self.activation(h) if self.activation else h\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation=F.relu, normalize=False, bias=False):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.weight = Parameter(torch.Tensor(self.in_channels, out_channels))\n",
    "        self.activation = activation\n",
    "        self.pool = pool\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "        row, col = edge_index\n",
    "        \n",
    "        out = torch.matmul(x, self.weight)\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "        out = self.activation(out)\n",
    "        out = scatter_mean(out[col], row, dim=0, dim_size=out.size(0))\n",
    "                \n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2, dim=-1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, hidden_dims, latent_dim):\n",
    "        super(GATEncoder, self).__init__()\n",
    "        self.num_nodes = input_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # GAT layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        \n",
    "        prev_dim = feature_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            if block_type == 'GCN':\n",
    "                self.layers.append(GCN(prev_dim, hidden_dim))\n",
    "            elif block_type == 'GAT':\n",
    "                self.layers.append(GAT(prev_dim, hidden_dim))\n",
    "            elif block_type == 'GraphSAGE'\n",
    "                self.layers.append(GraphSAGE(prev_dim, hidden_dim))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "            prev_dim = hidden_dim\n",
    "            \n",
    "        if block_type == 'GCN':\n",
    "            self.layers.append(GCN(prev_dim, latent_dim))\n",
    "        if block_type == 'GAT':\n",
    "            self.layers.append(GAT(prev_dim, latent_dim))\n",
    "        if block_type == 'GraphSAGE':\n",
    "            self.layers.append(GraphSAGE(prev_dim, latent_dim))\n",
    "        self.bns.append(nn.BatchNorm1d(latent_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(latent_dim * input_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        for layer, bn in zip(self.layers, self.bns):\n",
    "            x = F.relu(bn(layer(x, adj)))\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x_flat = x.view(-1)\n",
    "        z = self.fc(x_flat)\n",
    "        \n",
    "        return z\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, num_nodes, hidden_dims):\n",
    "        super(GATDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.hidden_dims = hidden_dims\n",
    "        \n",
    "        # Fully connected layer to expand z to node features\n",
    "        self.fc = nn.Linear(latent_dim, num_nodes * latent_dim)\n",
    "        self.bn0 = nn.BatchNorm1d(latent_dim)\n",
    "\n",
    "        # GAT layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        \n",
    "        prev_dim = latent_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            if block_type == 'GCN':\n",
    "                self.layers.append(GCN(prev_dim, hidden_dim))\n",
    "            elif block_type == 'GAT':\n",
    "                self.layers.append(GAT(prev_dim, hidden_dim))\n",
    "            elif block_type == 'GraphSAGE'\n",
    "                self.layers.append(GraphSAGE(prev_dim, hidden_dim))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        if block_type == 'GCN':\n",
    "            self.layers.append(GCN(prev_dim, num_nodes))\n",
    "        if block_type == 'GAT':\n",
    "            self.layers.append(GAT(prev_dim, num_nodes))\n",
    "        if block_type == 'GraphSAGE':\n",
    "            self.layers.append(GraphSAGE(prev_dim, num_nodes))\n",
    "        self.bns.append(nn.BatchNorm1d(num_nodes))\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.bn0(self.fc(z).view(self.num_nodes, self.latent_dim))\n",
    "        adj = torch.eye(self.num_nodes, device=z.device)\n",
    "        \n",
    "        for layer, bn in zip(self.layers, self.bns):\n",
    "            x = F.relu(bn(layer(x, adj)))\n",
    "\n",
    "        # Ensure symmetry of the adjacency matrix\n",
    "        adj_pred = (x + x.t()) / 2\n",
    "        \n",
    "        # Set the diagonal elements to zero (no self-connections)\n",
    "        adj_pred = adj_pred - torch.diag(torch.diag(adj_pred))\n",
    "        return adj_pred\n",
    "\n",
    "class GCRN(nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, latent_dim, encoder_hidden_dims, decoder_hidden_dims, num_layers=2):\n",
    "        super(GCRN, self).__init__()\n",
    "        set_seed(42)\n",
    "        self.hidden_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.encoder = Encoder(input_dim, feature_dim, encoder_hidden_dims, latent_dim)\n",
    "        self.gru = nn.GRU(latent_dim, self.hidden_dim, num_layers)\n",
    "        self.decoder = Decoder(latent_dim, input_dim, decoder_hidden_dims)  \n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        num_nodes, feature_dim = x.size()\n",
    "        \n",
    "        # Encode the current time point\n",
    "        z = self.encoder(x, adj)\n",
    "        z = z.unsqueeze(0).unsqueeze(0) \n",
    "        \n",
    "        # Initialize hidden states for GRU\n",
    "        h = torch.zeros(self.num_layers, 1, self.hidden_dim, device=x.device)  \n",
    "\n",
    "        # Update latent representation using the GRU\n",
    "        z, h = self.gru(z, h)\n",
    "        z = z.squeeze(0).squeeze(0) \n",
    "        \n",
    "        # Decode the updated latent representation to predict the adjacency matrix for the next time point\n",
    "        adj_pred = self.decoder(z)\n",
    "        \n",
    "        return adj_pred, z\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc_task_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
