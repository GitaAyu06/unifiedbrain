{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# domain-specific with innerproduct decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerProductDecoder(nn.Module):\n",
    "    def __init__(self, act=torch.sigmoid, dropout=0.):\n",
    "        super(InnerProductDecoder, self).__init__()\n",
    "        self.act = act\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        inp = F.dropout(inp, self.dropout, training=self.training)\n",
    "        x = torch.transpose(inp, dim0=0, dim1=1)\n",
    "        x = torch.mm(inp, x)\n",
    "        return self.act(x)\n",
    "\n",
    "\n",
    "class GCRN(nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, hidden_dim, num_layers=2):\n",
    "        super(GCRN, self).__init__()\n",
    "        self.encoder = GCNEncoder(input_dim, feature_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Create a vanilla GRU layer with the specified number of layers\n",
    "        self.gru = nn.GRU(feature_dim, hidden_dim, num_layers)\n",
    "        \n",
    "        # Use InnerProductDecoder for decoding\n",
    "        self.decoder = InnerProductDecoder()\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        num_nodes, feature_dim = x.size()\n",
    "        \n",
    "        # Encode the current time point\n",
    "        z, mu, logvar = self.encoder(x, adj)\n",
    "        z = z.unsqueeze(0).unsqueeze(0)  # (1, 1, feature_dim)\n",
    "        \n",
    "        # Initialize hidden states for GRU\n",
    "        h = torch.zeros(self.num_layers, 1, self.hidden_dim, device=x.device)  # (num_layers, batch_size, hidden_dim)\n",
    "        \n",
    "        # Update latent representation using the GRU\n",
    "        z, h = self.gru(z, h)\n",
    "        z = z.squeeze(0).squeeze(0) # (hidden_dim,)\n",
    "        \n",
    "        # Expand z to create node embeddings\n",
    "        z_expanded = z.unsqueeze(0).repeat(num_nodes, 1)  # (num_nodes, hidden_dim)\n",
    "        \n",
    "        # Decode the expanded latent representation to predict the adjacency matrix\n",
    "        adj_pred = self.decoder(z_expanded)\n",
    "        \n",
    "        return adj_pred, mu, logvar\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# domain-specific with gcn decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, num_nodes):\n",
    "        super(GCNDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        \n",
    "        # Fully connected layer to expand z to node features\n",
    "        self.fc = nn.Linear(latent_dim, num_nodes * latent_dim)\n",
    "        \n",
    "        # GCN layers\n",
    "        self.conv1 = GCN(latent_dim, latent_dim * 2)\n",
    "        self.bn1 = nn.BatchNorm1d(latent_dim * 2)\n",
    "        self.conv2 = GCN(latent_dim * 2, latent_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(latent_dim)\n",
    "        \n",
    "        # Fully connected layer to generate adjacency matrix\n",
    "        self.fc_adj = nn.Linear(latent_dim, num_nodes * num_nodes)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Expand z to initial node features\n",
    "        x = self.fc(z).view(self.num_nodes, self.latent_dim)\n",
    "        \n",
    "        # Initial adjacency matrix (identity matrix)\n",
    "        adj = torch.eye(self.num_nodes, device=z.device)\n",
    "        \n",
    "        # Pass through GCN layers\n",
    "        x = F.relu(self.bn1(self.conv1(x, adj)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.bn2(self.conv2(x, adj)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Generate adjacency matrix\n",
    "        adj_pred = torch.sigmoid(self.fc_adj(x).view(self.num_nodes, self.num_nodes))\n",
    "\n",
    "        # Ensure symmetry of the adjacency matrix\n",
    "        adj_pred = (adj_pred + adj_pred.T) / 2\n",
    "        \n",
    "        return adj_pred\n",
    "\n",
    "class GCRN(nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, hidden_dim, num_layers=2):\n",
    "        super(GCRN, self).__init__()\n",
    "        self.encoder = GCNEncoder(input_dim, feature_dim)\n",
    "        self.decoder = GCNDecoder(hidden_dim, input_dim)  # Assuming input_dim is the number of nodes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Create a vanilla GRU layer with the specified number of layers\n",
    "        self.gru = nn.GRU(feature_dim, hidden_dim, num_layers)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        num_nodes, feature_dim = x.size()\n",
    "        \n",
    "        # Encode the current time point\n",
    "        z, mu, logvar = self.encoder(x, adj)\n",
    "        z = z.unsqueeze(0).unsqueeze(0)  # (1, 1, feature_dim)\n",
    "        \n",
    "        # Initialize hidden states for GRU\n",
    "        h = torch.zeros(self.num_layers, 1, self.hidden_dim, device=x.device)  # (num_layers, batch_size, hidden_dim)\n",
    "        \n",
    "        # Update latent representation using the GRU\n",
    "        z, h = self.gru(z, h)\n",
    "        z = z.squeeze(0).squeeze(0) # (hidden_dim,)\n",
    "        \n",
    "        # Decode the updated latent representation to predict the adjacency matrix for the next time point\n",
    "        adj_pred = self.decoder(z)\n",
    "        \n",
    "        return adj_pred, mu, logvar\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# domain-specific with fully-connected layer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, num_nodes):\n",
    "        super(GCNDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        \n",
    "        # Fully connected layers to generate the adjacency matrix\n",
    "        self.fc1 = nn.Linear(latent_dim, latent_dim * 2)\n",
    "        self.fc2 = nn.Linear(latent_dim * 2, num_nodes * num_nodes)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Pass through fully connected layers\n",
    "        x = F.relu(self.fc1(z))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Reshape to the adjacency matrix\n",
    "        adj_pred = torch.sigmoid(x.view(self.num_nodes, self.num_nodes))\n",
    "\n",
    "        # Ensure symmetry of the adjacency matrix\n",
    "        adj_pred = (adj_pred + adj_pred.T) / 2\n",
    "        \n",
    "        return adj_pred\n",
    "\n",
    "class GCRN(nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, hidden_dim, num_layers=2):\n",
    "        super(GCRN, self).__init__()\n",
    "        self.encoder = GCNEncoder(input_dim, feature_dim)\n",
    "        self.decoder = GCNDecoder(hidden_dim, input_dim)  # Assuming input_dim is the number of nodes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Create a vanilla GRU layer with the specified number of layers\n",
    "        self.gru = nn.GRU(feature_dim, hidden_dim, num_layers)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        num_nodes, feature_dim = x.size()\n",
    "        \n",
    "        # Encode the current time point\n",
    "        z, mu, logvar = self.encoder(x, adj)\n",
    "        z = z.unsqueeze(0).unsqueeze(0)  # (1, 1, feature_dim)\n",
    "        \n",
    "        # Initialize hidden states for GRU\n",
    "        h = torch.zeros(self.num_layers, 1, self.hidden_dim, device=x.device)  # (num_layers, batch_size, hidden_dim)\n",
    "        \n",
    "        # Update latent representation using the GRU\n",
    "        z, h = self.gru(z, h)\n",
    "        z = z.squeeze(0).squeeze(0) # (hidden_dim,)\n",
    "        \n",
    "        # Decode the updated latent representation to predict the adjacency matrix for the next time point\n",
    "        adj_pred = self.decoder(z)\n",
    "        \n",
    "        return adj_pred, mu, logvar\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
